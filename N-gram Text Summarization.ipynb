{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba2f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\srina\\AppData\\Local\\Temp\\tmpvz58h3ko\\config.json as plain json\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "model_url = \"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\"\n",
    "predictor = Predictor.from_path(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d362827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rouge\n",
    "ROUGE = rouge.Rouge(metrics=['rouge-n'],\n",
    "                           max_n=1)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5078c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/SummarizationCSTitleAbstract03.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f996963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Microbiological Survey and Characterization</td>\n",
       "      <td>In our study, two dairy compost heaps and one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb 2 00 6 Non-Commutative Formal Groups in Pos...</td>\n",
       "      <td>We describe geometric non-commutative formal g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Alternating Mesh Quality Metric Scheme for ...</td>\n",
       "      <td>In the numerical solution of partial different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Researching Distance Learning Experiences Usin...</td>\n",
       "      <td>Qualitative case study is hardly a research te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Un Motor de Transformación de Modelos con Sopo...</td>\n",
       "      <td>Resumen. En la actualidad están apareciendo un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0      A Microbiological Survey and Characterization   \n",
       "1  eb 2 00 6 Non-Commutative Formal Groups in Pos...   \n",
       "2  An Alternating Mesh Quality Metric Scheme for ...   \n",
       "3  Researching Distance Learning Experiences Usin...   \n",
       "4  Un Motor de Transformación de Modelos con Sopo...   \n",
       "\n",
       "                                            abstract  \n",
       "0  In our study, two dairy compost heaps and one ...  \n",
       "1  We describe geometric non-commutative formal g...  \n",
       "2  In the numerical solution of partial different...  \n",
       "3  Qualitative case study is hardly a research te...  \n",
       "4  Resumen. En la actualidad están apareciendo un...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df = df.head(100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03edd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "# nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "\n",
    "# def resolve(corenlp_output):\n",
    "#     \"\"\" Transfer the word form of the antecedent to its associated pronominal anaphor(s) \"\"\"\n",
    "#     for coref in corenlp_output['corefs']:\n",
    "#         mentions = corenlp_output['corefs'][coref]\n",
    "#         antecedent = mentions[0]  # the antecedent is the first mention in the coreference chain\n",
    "#         for j in range(1, len(mentions)):\n",
    "#             mention = mentions[j]\n",
    "#             if mention['type'] == 'PRONOMINAL':\n",
    "#                 # get the attributes of the target mention in the corresponding sentence\n",
    "#                 target_sentence = mention['sentNum']\n",
    "#                 target_token = mention['startIndex'] - 1\n",
    "#                 # transfer the antecedent's word form to the appropriate token in the sentence\n",
    "#                 corenlp_output['sentences'][target_sentence - 1]['tokens'][target_token]['word'] = antecedent['text']\n",
    "\n",
    "\n",
    "# def get_resolved(corenlp_output):\n",
    "#     \"\"\"Return the \"resolved\" output sentence\"\"\"\n",
    "#     possessives = ['hers', 'his', 'their', 'theirs']\n",
    "#     output_sentence = \"\"  # Empty string to accumulate the output sentence\n",
    "    \n",
    "#     for sentence in corenlp_output['sentences']:\n",
    "#         for token in sentence['tokens']:\n",
    "#             output_word = token['word']\n",
    "#             if token['lemma'] in possessives or token['pos'] == 'PRP$':\n",
    "#                 output_word += \"'s\"\n",
    "#             output_word += token['after']\n",
    "#             output_sentence += output_word  # Append the output_word to the output_sentence\n",
    "    \n",
    "#     return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08ff7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(dataframe):\n",
    "    # Filling in Nan values\n",
    "    dataframe['abstract'] = dataframe['abstract'].fillna('This abstract does not exist')\n",
    "\n",
    "    # Getting tf-idf tables\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(dataframe['abstract'])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Generating best title for each abstract\n",
    "    summaries = []\n",
    "    scores = []\n",
    "    resolved_abstracts = []\n",
    "    for i in range(len(dataframe)):\n",
    "        abstract = dataframe.loc[i, 'abstract']\n",
    "        #print('\\nOriginal:', abstract)\n",
    "        \n",
    "#         # Stanford Anaphora Resolution\n",
    "#         output = nlp.annotate(abstract, properties= {'annotators':'dcoref','outputFormat':'json','ner.useSUTime':'false'})\n",
    "#         output = json.loads(output)\n",
    "#         resolve(output)\n",
    "#         abstract = get_resolved(output)\n",
    "#         print('\\nResolved:', abstract)\n",
    "        \n",
    "        # Allen Anaphora Resolution\n",
    "        prediction = predictor.predict(document=abstract)  # get prediction\n",
    "        abstract = predictor.coref_resolved(abstract)  # resolved text\n",
    "        resolved_abstracts.append(abstract)\n",
    "#         print('\\nResolved:', abstract)\n",
    "        \n",
    "        title = dataframe.loc[i, 'title']\n",
    "        tfidf_scores = tfidf_matrix[i].toarray().flatten()\n",
    "\n",
    "        # Sentence Tokenization\n",
    "        pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "        sentences = re.split(pattern, abstract)\n",
    "        sentences = [sentence for sentence in sentences if any(char.isalpha() for char in sentence)]\n",
    "\n",
    "        # N-gram scoring based on tf-idf values\n",
    "        max_score = -1\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split(' ')\n",
    "            ngrams_list = list(ngrams(words, len(title.split())))\n",
    "            for ngram in ngrams_list:\n",
    "                score = sum(tfidf_scores[vectorizer.vocabulary_.get(word.lower(), -1)] for word in ngram)\n",
    "                if (score > max_score):\n",
    "                    max_score = score\n",
    "                    summary = ' '.join(ngram)\n",
    "        \n",
    "        # Best n-gram is taken as title\n",
    "        summaries.append(summary)\n",
    "        # Rouge-1 score calculation\n",
    "        score = ROUGE.get_scores(summary, title)\n",
    "        p = score[\"rouge-1\"][\"p\"]\n",
    "        r = score[\"rouge-1\"][\"r\"]\n",
    "        f1 = score[\"rouge-1\"][\"f\"]\n",
    "        scores.append([p, r, f1])\n",
    "\n",
    "    dataframe['resolved abstract'] = resolved_abstracts\n",
    "    dataframe['summary'] = summaries\n",
    "    dataframe['rouge-1 score'] = scores\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0ff647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\OneDrive\\Desktop\\LinuxShared\\NLP\\Text Summarization\\projectsum\\sumenv\\lib\\site-packages\\allennlp\\modules\\token_embedders\\pretrained_transformer_embedder.py:385: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  num_effective_segments = (seq_lengths + self._max_length - 1) // self._max_length\n"
     ]
    }
   ],
   "source": [
    "df = summarize_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b452838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>resolved abstract</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge-1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Microbiological Survey and Characterization</td>\n",
       "      <td>In our study, two dairy compost heaps and one ...</td>\n",
       "      <td>In our study, two dairy compost heaps and one ...</td>\n",
       "      <td>and VRE in compost were</td>\n",
       "      <td>[0.2, 0.2, 0.20000000000000004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb 2 00 6 Non-Commutative Formal Groups in Pos...</td>\n",
       "      <td>We describe geometric non-commutative formal g...</td>\n",
       "      <td>We describe geometric non-commutative formal g...</td>\n",
       "      <td>formal groups in terms of a geometric commutat...</td>\n",
       "      <td>[0.4, 0.36363636363636365, 0.380952380952381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Alternating Mesh Quality Metric Scheme for ...</td>\n",
       "      <td>In the numerical solution of partial different...</td>\n",
       "      <td>In the numerical solution of partial different...</td>\n",
       "      <td>inefficient mesh quality metric with a more ef...</td>\n",
       "      <td>[0.5454545454545454, 0.5454545454545454, 0.545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Researching Distance Learning Experiences Usin...</td>\n",
       "      <td>Qualitative case study is hardly a research te...</td>\n",
       "      <td>Qualitative case study is hardly a research te...</td>\n",
       "      <td>is typical of most qualitative research to emp...</td>\n",
       "      <td>[0.3125, 0.35714285714285715, 0.3333333333333333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Un Motor de Transformación de Modelos con Sopo...</td>\n",
       "      <td>Resumen. En la actualidad están apareciendo un...</td>\n",
       "      <td>Resumen. En la actualidad están apareciendo un...</td>\n",
       "      <td>la arquitectura de un motor de transformación ...</td>\n",
       "      <td>[0.6428571428571429, 0.6428571428571429, 0.642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ExoMol molecular line lists-XXVI : spectra of ...</td>\n",
       "      <td>Line lists for the sulphur-containing molecule...</td>\n",
       "      <td>Line lists for the sulphur-containing molecule...</td>\n",
       "      <td>NS calculated line list includes around 2.8 mi...</td>\n",
       "      <td>[0.36363636363636365, 0.4, 0.380952380952381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Multiround Private Information Retrieval: Capa...</td>\n",
       "      <td>Private information retrieval (PIR) is the pro...</td>\n",
       "      <td>Private information retrieval (PIR) is the pro...</td>\n",
       "      <td>The capacity of PIR has recently been characte...</td>\n",
       "      <td>[0.125, 0.125, 0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Efficient Integral Equation Algorithms and The...</td>\n",
       "      <td>Efficient Integral Equation Algorithms and The...</td>\n",
       "      <td>Efficient Integral Equation Algorithms and The...</td>\n",
       "      <td>frequency domain surface integral equation pro...</td>\n",
       "      <td>[0.3, 0.3, 0.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Are the Determinants of Markup Size Industry-S...</td>\n",
       "      <td>The aim of this paper is to identify factors t...</td>\n",
       "      <td>The aim of this paper is to identify factors t...</td>\n",
       "      <td>affect the pricing policy in Slovenian manufac...</td>\n",
       "      <td>[0.5384615384615384, 0.5, 0.5185185185185186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Distributed Recovery of Node Failures in Wirel...</td>\n",
       "      <td>Wireless sensor and actor networks (WSANs) add...</td>\n",
       "      <td>Wireless sensor and actor networks (WSANs) add...</td>\n",
       "      <td>the connectivity restoration process is to loc...</td>\n",
       "      <td>[0.09090909090909091, 0.09090909090909091, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0       A Microbiological Survey and Characterization   \n",
       "1   eb 2 00 6 Non-Commutative Formal Groups in Pos...   \n",
       "2   An Alternating Mesh Quality Metric Scheme for ...   \n",
       "3   Researching Distance Learning Experiences Usin...   \n",
       "4   Un Motor de Transformación de Modelos con Sopo...   \n",
       "..                                                ...   \n",
       "95  ExoMol molecular line lists-XXVI : spectra of ...   \n",
       "96  Multiround Private Information Retrieval: Capa...   \n",
       "97  Efficient Integral Equation Algorithms and The...   \n",
       "98  Are the Determinants of Markup Size Industry-S...   \n",
       "99  Distributed Recovery of Node Failures in Wirel...   \n",
       "\n",
       "                                             abstract  \\\n",
       "0   In our study, two dairy compost heaps and one ...   \n",
       "1   We describe geometric non-commutative formal g...   \n",
       "2   In the numerical solution of partial different...   \n",
       "3   Qualitative case study is hardly a research te...   \n",
       "4   Resumen. En la actualidad están apareciendo un...   \n",
       "..                                                ...   \n",
       "95  Line lists for the sulphur-containing molecule...   \n",
       "96  Private information retrieval (PIR) is the pro...   \n",
       "97  Efficient Integral Equation Algorithms and The...   \n",
       "98  The aim of this paper is to identify factors t...   \n",
       "99  Wireless sensor and actor networks (WSANs) add...   \n",
       "\n",
       "                                    resolved abstract  \\\n",
       "0   In our study, two dairy compost heaps and one ...   \n",
       "1   We describe geometric non-commutative formal g...   \n",
       "2   In the numerical solution of partial different...   \n",
       "3   Qualitative case study is hardly a research te...   \n",
       "4   Resumen. En la actualidad están apareciendo un...   \n",
       "..                                                ...   \n",
       "95  Line lists for the sulphur-containing molecule...   \n",
       "96  Private information retrieval (PIR) is the pro...   \n",
       "97  Efficient Integral Equation Algorithms and The...   \n",
       "98  The aim of this paper is to identify factors t...   \n",
       "99  Wireless sensor and actor networks (WSANs) add...   \n",
       "\n",
       "                                              summary  \\\n",
       "0                             and VRE in compost were   \n",
       "1   formal groups in terms of a geometric commutat...   \n",
       "2   inefficient mesh quality metric with a more ef...   \n",
       "3   is typical of most qualitative research to emp...   \n",
       "4   la arquitectura de un motor de transformación ...   \n",
       "..                                                ...   \n",
       "95  NS calculated line list includes around 2.8 mi...   \n",
       "96  The capacity of PIR has recently been characte...   \n",
       "97  frequency domain surface integral equation pro...   \n",
       "98  affect the pricing policy in Slovenian manufac...   \n",
       "99  the connectivity restoration process is to loc...   \n",
       "\n",
       "                                        rouge-1 score  \n",
       "0                     [0.2, 0.2, 0.20000000000000004]  \n",
       "1       [0.4, 0.36363636363636365, 0.380952380952381]  \n",
       "2   [0.5454545454545454, 0.5454545454545454, 0.545...  \n",
       "3   [0.3125, 0.35714285714285715, 0.3333333333333333]  \n",
       "4   [0.6428571428571429, 0.6428571428571429, 0.642...  \n",
       "..                                                ...  \n",
       "95      [0.36363636363636365, 0.4, 0.380952380952381]  \n",
       "96                              [0.125, 0.125, 0.125]  \n",
       "97                                    [0.3, 0.3, 0.3]  \n",
       "98      [0.5384615384615384, 0.5, 0.5185185185185186]  \n",
       "99  [0.09090909090909091, 0.09090909090909091, 0.0...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6abf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aim of this paper is to identify factors that affect the pricing policy in Slovenian manufacturing firms in terms of the markup size and, most of all, to explicitly account for the possibility of differences in pricing procedures among manufacturing industries. Accordingly, the analysis of the dynamic panel is carried out on an industry-by-industry basis, allowing the coefficients on the markup determinants to vary across industries. We find that the oligopoly theory of markup determination for the most part holds for the manufacturing sector as a whole, although large variability in markup determinants exists across industries within the Slovenian manufacturing. Our main conclusion is that each industry should be investigated separately in detail in order to assess the precise role of markup factors in the markup-determination process.\n"
     ]
    }
   ],
   "source": [
    "print(df['abstract'][98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f7ec78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affect the pricing policy in Slovenian manufacturing firms in terms of the markup\n"
     ]
    }
   ],
   "source": [
    "print(df['summary'][98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf018ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the Determinants of Markup Size Industry-Specific? The Case of Slovenian Manufacturing Firms\n"
     ]
    }
   ],
   "source": [
    "print(df['title'][98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8979de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26607181165927296, 0.2665639314432894, 0.26567089086657686]\n"
     ]
    }
   ],
   "source": [
    "p_sum = r_sum = f1_sum = 0\n",
    "for score in df['rouge-1 score']:\n",
    "    p_sum += score[0]\n",
    "    r_sum += score[1]\n",
    "    f1_sum += score[2]\n",
    "total = len(df['rouge-1 score'])\n",
    "avg = [p_sum/total, r_sum/total, f1_sum/total]\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d8e9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to CSV file\n",
    "df.to_csv('combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c1d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumenv",
   "language": "python",
   "name": "sumenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
